# -*- coding: utf-8 -*-
"""LR_2_task_3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ByygT2ddFIr8IJDcJxmQYONloJyBaNII
"""

import pandas as pd
import matplotlib.pyplot as plt
from pandas.plotting import scatter_matrix
from sklearn.datasets import load_iris

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–±–æ—Ä—É –¥–∞–Ω–∏—Ö iris
iris = load_iris()
X = iris.data
y = iris.target
df = pd.DataFrame(X, columns=iris.feature_names)
df['class'] = iris.target

# –î—Ä—É–∫ –±–∞–∑–æ–≤–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
print("–ù–∞–∑–≤–∏ –∫–ª–∞—Å—ñ–≤:", iris.target_names)
print("–ù–∞–∑–≤–∏ –æ–∑–Ω–∞–∫:", iris.feature_names)
print("–†–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å:", X.shape)
print(df.head())

# üìä Boxplot
df.drop('class', axis=1).plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)
plt.suptitle("Boxplot –æ–∑–Ω–∞–∫")
plt.show()

# üìä Histogram
df.drop('class', axis=1).hist()
plt.suptitle("Histogram –æ–∑–Ω–∞–∫")
plt.show()

# üìä Scatter matrix
scatter_matrix(df.drop('class', axis=1))
plt.suptitle("Scatter matrix –æ–∑–Ω–∞–∫")
plt.show()

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
import matplotlib.pyplot as plt

# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ X —Ç–∞ y
X = df.drop('class', axis=1).values
y = df['class'].values

# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—É —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω—É –≤–∏–±—ñ—Ä–∫—É
X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=1)

# –ü–æ–±—É–¥–æ–≤–∞ –º–æ–¥–µ–ª–µ–π
models = []
models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(gamma='auto')))

# –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
results = []
names = []
for name, model in models:
    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    print('%s: %.2f (¬±%.2f)' % (name, cv_results.mean(), cv_results.std()))

# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π –≥—Ä–∞—Ñ—ñ–∫–æ–º
plt.boxplot(results, labels=names)
plt.title('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤')
plt.ylabel('–¢–æ—á–Ω—ñ—Å—Ç—å (Accuracy)')
plt.grid(True)
plt.show()

import numpy as np

# üîÆ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–æ–≤–æ—ó –∫–≤—ñ—Ç–∫–∏
X_new = np.array([[5, 2.9, 1, 0.2]])
prediction = model.predict(X_new)
print("\n–ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –Ω–æ–≤–æ—ó –∫–≤—ñ—Ç–∫–∏:", prediction[0])
print("–¶–µ —Å–æ—Ä—Ç:", iris.target_names[prediction[0]])